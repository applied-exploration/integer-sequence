{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rnn.rnn_plain import RNN_Plain\r\n",
    "from models.rnn.rnn_attention import RNN_Attention\r\n",
    "\r\n",
    "# from lang_numbers import load_data_int_seq\r\n",
    "from lang_numbers import load_data_int_seq\r\n",
    "from utils import accuracy_score\r\n",
    "\r\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  8 12 16 20 24 28 32]]\n",
      "-\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "t\n",
      "+\n",
      "3\n",
      "*\n",
      "t\n",
      "-\n",
      "1\n",
      "+\n",
      "1\n",
      "7\n",
      "+\n",
      "4\n",
      "*\n",
      "9\n",
      "-\n",
      "1\n",
      "-\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(13, 28)\n",
      "  (gru): GRU(28, 256, num_layers=2, dropout=0.3)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embedding): Embedding(11, 28)\n",
      "  (gru): GRU(28, 256, num_layers=2, dropout=0.3)\n",
      "  (out): Linear(in_features=256, out_features=11, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "algo = RNN_Plain(symbols = \"+*-0123456789t\", \r\n",
    "output_sequence_length = 9, \r\n",
    "encoded_seq_length = 9, \r\n",
    "num_epochs = 1, \r\n",
    "input_size = input_lang.n_words, \r\n",
    "hidden_size = 256, \r\n",
    "output_size=output_lang.n_words, \r\n",
    "embedding_size = 28, \r\n",
    "batch_size = 1, \r\n",
    "num_gru_layers = 2,\r\n",
    "dropout_prob = 0.3,\r\n",
    "calc_magnitude_on=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4,8,12,16,20,24,28,32']\n",
      "test_char  tensor([[7],\n",
      "        [0]], device='cuda:0')\n",
      "[[tensor([[7],\n",
      "        [0]], device='cuda:0')], [tensor([[11],\n",
      "        [ 0]], device='cuda:0')], [tensor([[4],\n",
      "        [0]], device='cuda:0'), tensor([[5],\n",
      "        [0]], device='cuda:0')]]\n",
      "[tensor([[7],\n",
      "        [0]], device='cuda:0')]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-208ee6d978f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_plain.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_lang, output_lang, data)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;31m# --- with own minibatching --- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0minput_tensor_minibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_minibatch_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[0mtarget_tensor_minibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_plain.py\u001b[0m in \u001b[0;36mcreate_minibatch_input\u001b[1;34m(self, data, batch_size, lang)\u001b[0m\n\u001b[0;32m    128\u001b[0m         encoded_dataset = [[tensorFromSentence(lang, number) \n\u001b[0;32m    129\u001b[0m                         for number in decimalized_dataset[random.randrange(0, len(data))]]\n\u001b[1;32m--> 130\u001b[1;33m                         for i in range(batch_size)]\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_plain.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m         encoded_dataset = [[tensorFromSentence(lang, number) \n\u001b[0;32m    129\u001b[0m                         for number in decimalized_dataset[random.randrange(0, len(data))]]\n\u001b[1;32m--> 130\u001b[1;33m                         for i in range(batch_size)]\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_plain.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         encoded_dataset = [[tensorFromSentence(lang, number) \n\u001b[1;32m--> 129\u001b[1;33m                         for number in decimalized_dataset[random.randrange(0, len(data))]]\n\u001b[0m\u001b[0;32m    130\u001b[0m                         for i in range(batch_size)]\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_utils.py\u001b[0m in \u001b[0;36mtensorFromSentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\rnn_utils.py\u001b[0m in \u001b[0;36mindexesFromSentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;34m','\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m    661\u001b[0m         raise RuntimeError(\n\u001b[0;32m    662\u001b[0m             \u001b[1;34m\"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m         )\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."
     ]
    }
   ],
   "source": [
    "algo.train(input_lang, output_lang, train)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain RNN with Magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magn_algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "magn_algo.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = magn_algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Attention-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\n",
    "algo_attn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention with magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn_magn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "algo_attn_magn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn_magn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "m = nn.LogSoftmax()\r\n",
    "input = torch.randn(2, 3)\r\n",
    "print(input)\r\n",
    "output = m(input)\r\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D loss example (used, for example, with image inputs)\r\n",
    "N, C = 5, 4\r\n",
    "loss = nn.NLLLoss()\r\n",
    "\r\n",
    "# input is of size N x C x height x width\r\n",
    "data = torch.randn(N, 16, 10, 10)\r\n",
    "conv = nn.Conv2d(16, C, (3, 3))\r\n",
    "m = nn.LogSoftmax(dim=1)\r\n",
    "\r\n",
    "# print(data.shape)\r\n",
    "activated = m(conv(data))\r\n",
    "print(\"output: \", activated.shape)\r\n",
    "\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\r\n",
    "print(\"target: \", target.shape)\r\n",
    "output = loss(activated, target)\r\n",
    "\r\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\r\n",
    "loss = nn.NLLLoss()\r\n",
    "# input is of size N x C = 3 x 5\r\n",
    "# input = minibatchsize, number of categories\r\n",
    "\r\n",
    "input = torch.randn(3, 5, requires_grad=True)\r\n",
    "# print(input.shape)\r\n",
    "activation = m(input)\r\n",
    "print(activation.shape)\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.tensor([1, 0, 4])\r\n",
    "print(target.shape)\r\n",
    "output = loss(activation, target)\r\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler\r\n",
    "\r\n",
    "stuff_to_evaluate = [1,2,3]\r\n",
    "def function_to_evaluate(stuff_to_evaluate):\r\n",
    "    pass\r\n",
    "\r\n",
    "lp = LineProfiler()\r\n",
    "lp_wrapper = lp(function_to_evaluate)\r\n",
    "lp_wrapper(stuff_to_evaluate)\r\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}