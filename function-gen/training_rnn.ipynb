{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('deeplearning': conda)"
  },
  "interpreter": {
   "hash": "a630840cc17be2676cbce8189d2083744dc2f6895f9cfddc5644aa2e06831cd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from models.rnn.rnn_plain import RNN_Plain\n",
    "from models.rnn.rnn_attention import RNN_Attention\n",
    "\n",
    "from lang import load_data_int_seq\n",
    "from utils import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()"
   ]
  },
  {
   "source": [
    "## Plain RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 31s (- 4m 46s) (500 10%) 1.7721\n",
      "1m 4s (- 4m 18s) (1000 20%) 1.6021\n",
      "1m 37s (- 3m 46s) (1500 30%) 1.5646\n",
      "2m 9s (- 3m 14s) (2000 40%) 1.5432\n",
      "2m 42s (- 2m 42s) (2500 50%) 1.5284\n",
      "3m 14s (- 2m 9s) (3000 60%) 1.5266\n",
      "3m 45s (- 1m 36s) (3500 70%) 1.4956\n",
      "4m 19s (- 1m 4s) (4000 80%) 1.5039\n",
      "4m 52s (- 0m 32s) (4500 90%) 1.4984\n",
      "5m 26s (- 0m 0s) (5000 100%) 1.4991\n"
     ]
    }
   ],
   "source": [
    "algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\n",
    "algo.train(train, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t-t+t*t-t',\n",
       " 't*t*t*t*t',\n",
       " 't+t-t+t-t',\n",
       " 't-t*t*t-t',\n",
       " 't*t*t*t*t',\n",
       " 't-t-t-t-t',\n",
       " 't-t+t+t-t',\n",
       " 't+t+t+t*t',\n",
       " 't+t-t+t-t',\n",
       " '1-t-t+t-t',\n",
       " 't-t*t*t*t',\n",
       " 't*t+t*t*t',\n",
       " 't*t*t*t*t',\n",
       " 't+t*t*t*t',\n",
       " 't+t+t+t*t',\n",
       " 't+t+t*t*t',\n",
       " 't-t+t-t+t',\n",
       " 't+t+t+t*t',\n",
       " 't+t*t*t-t',\n",
       " 't+t+t+t*t',\n",
       " 't+t+t+t*t',\n",
       " 't-t+t+t-t',\n",
       " 't-t-t*t-t',\n",
       " 't-t-t-t-t',\n",
       " 't-t-t*t-t']"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "pred = algo.infer(X_test[:1000], input_lang, output_lang)\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "accuracy_score(pred, test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plain RNN with Magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 37s (- 5m 41s) (500 10%) 1.7497\n",
      "1m 16s (- 5m 6s) (1000 20%) 1.5925\n",
      "1m 55s (- 4m 30s) (1500 30%) 1.5723\n",
      "2m 33s (- 3m 50s) (2000 40%) 1.5489\n",
      "3m 11s (- 3m 11s) (2500 50%) 1.5250\n",
      "3m 51s (- 2m 34s) (3000 60%) 1.5174\n",
      "4m 31s (- 1m 56s) (3500 70%) 1.5146\n",
      "5m 11s (- 1m 17s) (4000 80%) 1.4989\n",
      "5m 49s (- 0m 38s) (4500 90%) 1.4835\n",
      "6m 28s (- 0m 0s) (5000 100%) 1.4935\n"
     ]
    }
   ],
   "source": [
    "magn_algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "magn_algo.train(train, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t-t+t-t*t',\n",
       " 't*t*t*t-t',\n",
       " 't-t-t+t-t',\n",
       " 't+t-t+t+t',\n",
       " 't+t+t+t*t',\n",
       " 't-t+t-t+t',\n",
       " 't-t-t-t-t',\n",
       " 't+t+t+t*t',\n",
       " 't-t-t+t-t',\n",
       " 't-t-t-t-t',\n",
       " 't-t*t*t-t',\n",
       " 't+t+t+t+t',\n",
       " 't*t*t*t*t',\n",
       " 't+t+t+t*t',\n",
       " 't+t+t+t+t',\n",
       " 't*t*t*t*t',\n",
       " 't-t+t-t+t',\n",
       " 't+t+t+t+t',\n",
       " 't-t+t+t*t',\n",
       " 't+t+t+t+t',\n",
       " 't+t+t+t+t',\n",
       " 't-t-t-t-t',\n",
       " 't-t-t-t-t',\n",
       " 't+t-t+t+t',\n",
       " 't-t-t-t-t']"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "pred = magn_algo.infer(X_test[:1000], input_lang, output_lang)\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "accuracy_score(pred, test[:1000])"
   ]
  },
  {
   "source": [
    "## Â Attention-based"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 42s (- 6m 18s) (500 10%) 1.4957\n",
      "1m 22s (- 5m 30s) (1000 20%) 1.4910\n",
      "2m 2s (- 4m 45s) (1500 30%) 1.4914\n",
      "2m 46s (- 4m 9s) (2000 40%) 1.4649\n",
      "3m 29s (- 3m 29s) (2500 50%) 1.4607\n",
      "4m 12s (- 2m 48s) (3000 60%) 1.4557\n",
      "4m 55s (- 2m 6s) (3500 70%) 1.4536\n",
      "5m 37s (- 1m 24s) (4000 80%) 1.4843\n",
      "6m 22s (- 0m 42s) (4500 90%) 1.4842\n",
      "7m 4s (- 0m 0s) (5000 100%) 1.4551\n"
     ]
    }
   ],
   "source": [
    "algo_attn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\n",
    "algo.train(train, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['44+++y+yy',\n",
       " '441t41t41',\n",
       " '74141++++',\n",
       " '4414t4+4+',\n",
       " '414++yyyy',\n",
       " '44t44++yy',\n",
       " '741++y4t4',\n",
       " '44+yyyyyy',\n",
       " '74++yyy+y',\n",
       " '441+++++y',\n",
       " '44141t4t4',\n",
       " '44+++++++',\n",
       " '44+1+++41',\n",
       " '44++4141+',\n",
       " '441+++y+y',\n",
       " '74++yyyyy',\n",
       " '41+++y+yy',\n",
       " '441t41t41',\n",
       " '441t4t4t4',\n",
       " '4++4414t4',\n",
       " '44141t41+',\n",
       " '4++++++++',\n",
       " '441++++++',\n",
       " '44141t41t',\n",
       " '441t4t41t']"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "pred = algo_attn.infer(X_test[:1000], input_lang, output_lang)\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "accuracy_score(pred, test[:1000])"
   ]
  },
  {
   "source": [
    "### Attention with magnitude loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 41s (- 6m 15s) (500 10%) 1.4393\n",
      "1m 19s (- 5m 19s) (1000 20%) 1.4423\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-635118b9fa81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malgo_attn_magn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN_Attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"+*-0123456789t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_magnitude_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dev/integer-sequence/function-gen/models/rnn/rnn_plain.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, input_lang, output_lang)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             loss = train(input_tensor, target_tensor, self.encoder,\n\u001b[0m\u001b[1;32m     87\u001b[0m                         self.decoder, encoder_optimizer, decoder_optimizer, criterion, input_lang, output_lang, self.calc_magnitude )\n\u001b[1;32m     88\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/integer-sequence/function-gen/models/rnn/combined_networks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, input_lang, output_lang, with_attention, calc_magnitude, max_length)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# detach from history as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo_attn_magn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "algo.train(train, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn_magn.infer(X_test[:1000], input_lang, output_lang)\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, test[:1000])"
   ]
  }
 ]
}