{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from models.rnn.rnn_plain import RNN_Plain\n",
    "from models.rnn.rnn_attention import RNN_Attention\n",
    "\n",
    "from lang import load_data_int_seq\n",
    "from utils import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size\n",
      "2564\n"
     ]
    }
   ],
   "source": [
    "algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 2, input_size=input_lang.n_words, hidden_size=256, output_size=output_lang.n_words, embedding_size = 28, calc_magnitude_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1])\n",
      "9\n",
      "input_tensor[ei]\n",
      "tensor([5])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([5])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.0538, -0.6164,  1.0345, -0.1548,  0.9399, -0.1107,  0.4394,\n",
      "          -1.4853, -0.3117, -0.6009,  0.2666, -0.6184,  0.6373,  0.7697,\n",
      "          -0.0951, -0.1351,  1.7434, -0.7814, -0.8371, -0.6605, -0.5779,\n",
      "          -0.4593, -1.9816,  0.5197,  0.3522,  1.2072, -0.2372, -0.2047]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([10])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([10])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 0.8958,  0.2068, -1.8497,  1.0690, -0.4614, -0.4627, -1.8680,\n",
      "           0.7912,  1.4112, -1.1326,  0.0558, -1.0916,  0.1323,  0.3884,\n",
      "           0.5784, -0.9356, -1.6586,  0.4249, -1.0487,  0.7925,  0.9011,\n",
      "           1.2623, -0.0264,  1.2575,  2.4449,  1.4748, -0.3584, -0.5302]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([11])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([11])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 1.1099,  0.4308, -1.4962,  0.5297,  0.2892,  0.0924,  0.8583,\n",
      "          -0.6768, -0.2170, -0.5713, -0.2995,  0.0140, -0.6574, -0.4664,\n",
      "          -1.3403, -1.2085,  0.0855,  1.1640, -0.6737,  1.1122,  1.3550,\n",
      "          -0.5732, -1.2833, -0.8528, -0.3491, -0.2454, -0.8143, -1.3002]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([12])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([12])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.8758, -1.0519,  0.4019, -0.3812, -0.7621, -2.6677,  0.5826,\n",
      "           0.7403, -0.3907,  1.3820, -0.2104,  0.4638,  0.1035,  0.7806,\n",
      "           0.4445, -0.0801, -0.3846,  0.8722, -1.5240, -1.1246, -1.6268,\n",
      "          -0.8320, -0.6282,  0.5236,  0.3672,  0.4303,  0.9159, -0.3296]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([6])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([6])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 0.4010,  2.1280,  0.2210, -0.4968,  1.3498, -3.2646, -0.2925,\n",
      "          -0.0055,  0.1755,  0.1720,  1.2635,  0.7959, -0.5126,  1.8007,\n",
      "           0.6987, -0.2799, -0.9701, -1.4470,  1.0500, -0.5452, -1.1674,\n",
      "          -0.0970,  0.7032, -0.4352, -0.7849, -1.5198,  0.3430,  0.7112]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([13])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([13])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.8398, -1.4878, -0.6339,  0.9540, -0.3912,  0.4527,  0.2792,\n",
      "           1.1822,  0.7158,  1.5053,  1.4848,  0.5868, -2.6825, -0.3391,\n",
      "          -0.6302, -0.7462,  0.3759,  0.8002, -0.3275,  0.4101,  0.4064,\n",
      "          -0.2413,  0.0389, -0.4985,  0.3864, -0.4010,  1.2064,  1.5369]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([14])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([14])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 0.5188, -0.4839, -1.4993, -0.4863,  1.2009, -2.0058,  0.1251,\n",
      "          -0.1136,  0.6969, -0.2817,  0.6173,  0.2359, -1.9873,  1.5016,\n",
      "          -0.5317,  0.5028, -0.3057, -0.7839,  0.5150,  0.9167, -0.2094,\n",
      "          -0.3906, -0.3546,  1.4939,  1.1929,  0.9405, -1.5931, -1.3328]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([15])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([15])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.8308,  0.0721, -0.3047, -0.7077,  1.3664, -0.3763,  1.6687,\n",
      "          -0.2379, -0.1800,  0.2998,  1.0954,  0.0674,  0.5170,  1.2789,\n",
      "           0.4205, -0.5052,  0.8586,  0.1422,  1.8489, -0.3480, -0.4585,\n",
      "          -1.4417,  0.1865,  0.4408, -0.1646, -0.4628, -1.2840, -0.3083]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([0])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([0])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.1332, -0.4230, -0.2911,  0.8020,  0.3357,  0.1474,  0.2328,\n",
      "           0.1853, -0.4932,  0.7918, -0.3782, -1.0372,  0.7524,  0.6522,\n",
      "           0.5999, -0.4347, -0.0711,  1.2061,  0.3594,  0.2104,  1.0374,\n",
      "          -1.6273, -1.7099, -1.2079,  0.9523, -1.7304, -0.0788, -0.8537]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "0m 0s (- 0m 0s) (1 50%) 2.7815\n",
      "torch.Size([9, 1])\n",
      "9\n",
      "input_tensor[ei]\n",
      "tensor([29])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([29])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 0.8945,  1.3315,  0.9743,  0.3109,  1.6957,  0.1180,  0.1472,\n",
      "          -2.6391,  0.5804,  0.4542, -2.4950,  1.9395, -0.5774,  1.4028,\n",
      "           1.7536, -1.8780, -0.0689, -1.2042,  0.5674, -0.9135,  0.3169,\n",
      "          -0.2400,  0.4937, -0.5610, -1.5317, -0.5275, -0.8360, -0.8070]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([43])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([43])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 1.3897,  1.1978, -1.0464,  0.5460,  0.9312, -0.6416,  0.5005,\n",
      "           0.8811, -0.0672, -1.0370, -0.6095,  0.0281,  2.3422,  0.0856,\n",
      "          -0.2133,  0.1804,  0.3876, -1.2433, -0.3678, -0.6543,  1.1039,\n",
      "          -0.8674, -0.8165, -0.0207, -0.8649, -1.4216,  0.1818,  0.1163]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([33])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([33])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 1.3589,  0.5593, -0.3829,  0.0080, -0.3331,  0.1701, -1.4439,\n",
      "          -0.3980,  0.3619, -0.5566, -0.1456, -0.1870, -0.6139,  1.3173,\n",
      "          -0.9872,  0.0086, -1.0929,  1.4981, -0.7345, -0.6578, -1.0577,\n",
      "          -0.3146,  1.6256,  1.9321, -0.3611,  0.6960,  0.5341,  0.1628]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([16])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([16])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.2455, -0.1966,  2.4936,  0.8940, -0.9227, -1.4998,  1.5047,\n",
      "          -0.4843,  1.0791,  2.4783,  0.6162,  1.0762, -0.1500, -0.1698,\n",
      "           0.6771, -0.8835,  1.0346,  1.8433,  0.7488, -0.3344, -1.0464,\n",
      "           1.1418, -1.0133, -0.0094, -0.3044,  1.7454,  1.2765,  0.0716]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([20])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([20])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 1.2152,  1.1158,  1.7901,  1.3712, -1.2737, -0.4043,  0.5599,\n",
      "          -1.1609,  0.4437, -0.3346, -1.2139, -1.1541, -0.8214,  0.3710,\n",
      "           1.3027, -0.4995, -1.1632, -0.0444, -0.0254, -1.5427,  0.0389,\n",
      "          -0.0222, -0.2526,  0.6873,  0.6295,  0.9610,  1.6836, -0.1939]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([35])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([35])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.2242,  1.2084,  0.7923,  0.7682, -0.3802,  0.0382,  0.0115,\n",
      "           0.2388,  0.6622, -0.3714, -0.3965,  0.6233, -0.3177, -2.1470,\n",
      "           0.8484, -0.8348,  0.3520,  0.1119, -1.0563,  0.9559, -0.1077,\n",
      "           1.2416,  0.7259,  1.4349, -0.5061,  1.3833, -0.0209, -0.0769]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([54])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([54])\n",
      "<=== Encoder Input\n",
      "tensor([[[-1.1730,  1.7580,  0.0532,  0.5762,  1.0649,  1.6200, -0.9392,\n",
      "           0.8873,  2.1462,  0.7613,  0.2551,  0.0365, -0.0227, -0.0778,\n",
      "           1.4619,  0.6190,  0.5742, -1.3278,  0.4847, -1.0433, -0.2177,\n",
      "           0.0653, -0.3542,  0.8877, -1.0824,  0.4527, -0.8925, -0.7909]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([55])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([55])\n",
      "<=== Encoder Input\n",
      "tensor([[[ 1.0997,  0.9462, -0.5037, -0.0586, -0.9293,  0.8493, -0.9902,\n",
      "           1.6482,  1.6619, -1.1121, -1.4341, -0.1238, -0.7431, -0.5015,\n",
      "           0.3320,  1.8219, -1.5325,  1.5055, -2.5314, -1.6060, -0.2376,\n",
      "           0.0725,  0.5213,  1.1306,  1.6749, -1.5403, -0.4274, -0.0120]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "input_tensor[ei]\n",
      "tensor([0])\n",
      "===> Encoder Input\n",
      "input\n",
      "tensor([0])\n",
      "<=== Encoder Input\n",
      "tensor([[[-0.1333, -0.4230, -0.2910,  0.8020,  0.3357,  0.1472,  0.2328,\n",
      "           0.1854, -0.4931,  0.7918, -0.3782, -1.0372,  0.7524,  0.6522,\n",
      "           0.5999, -0.4347, -0.0711,  1.2061,  0.3594,  0.2104,  1.0373,\n",
      "          -1.6273, -1.7099, -1.2079,  0.9523, -1.7302, -0.0789, -0.8537]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "0m 0s (- 0m 0s) (2 100%) 2.7859\n"
     ]
    }
   ],
   "source": [
    "algo.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(',' in '-7,-6,-5,-4,-3,-2,-1,0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('-7,-6,-5,-4,-3,-2,-1,0' is not '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain RNN with Magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magn_algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "magn_algo.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = magn_algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â Attention-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\n",
    "algo_attn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention with magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn_magn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "algo_attn_magn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn_magn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}