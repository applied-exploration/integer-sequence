{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rnn.rnn_plain import RNN_Plain\n",
    "from models.rnn.rnn_attention import RNN_Attention\n",
    "\n",
    "from lang import load_data_int_seq\n",
    "from utils import accuracy_score\n",
    "from models.rnn.combined_networks import train_report, Loss\n",
    "import wandb\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maexplore\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.33<br/>\n                Syncing run <strong style=\"color:#cdcd00\">fresh-haze-33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/aexplore/integer-sequence-function-gen\" target=\"_blank\">https://wandb.ai/aexplore/integer-sequence-function-gen</a><br/>\n                Run page: <a href=\"https://wandb.ai/aexplore/integer-sequence-function-gen/runs/3v5xg9oy\" target=\"_blank\">https://wandb.ai/aexplore/integer-sequence-function-gen/runs/3v5xg9oy</a><br/>\n                Run data is saved locally in <code>/Users/mark/Dev/integer-sequence/function-gen/wandb/run-20210716_190540-3v5xg9oy</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<h1>Run(3v5xg9oy)</h1><iframe src=\"https://wandb.ai/aexplore/integer-sequence-function-gen/runs/3v5xg9oy\" style=\"border:none;width:100%;height:400px\"></iframe>",
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x13c235fd0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num_batch:  32\nEncoderRNN(\n  (embedding): Embedding(4300, 256)\n  (gru): GRU(256, 512)\n)\nDecoderRNN(\n  (embedding): Embedding(16, 256)\n  (gru): GRU(256, 512)\n  (out): Linear(in_features=512, out_features=16, bias=True)\n  (softmax): LogSoftmax(dim=1)\n)\n"
     ]
    }
   ],
   "source": [
    "algo = RNN_Plain(symbols = \"+*-0123456789t\", \n",
    "output_sequence_length = 9, \n",
    "encoded_seq_length = 9, \n",
    "num_epochs = 10000, \n",
    "input_size = input_lang.n_words, \n",
    "hidden_size = 512, \n",
    "output_size=output_lang.n_words, \n",
    "embedding_size = 256, \n",
    "batch_size = 32, \n",
    "num_gru_layers = 1,\n",
    "dropout_prob = 0.,\n",
    "loss=Loss.NLL_Plus_MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE\n",
      "Loss tensor(15.4954, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6754, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4158, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9181, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4945, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3789, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6641, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5739, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7530, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1538, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4702, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1066, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6829, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1884, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3380, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5280, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0192, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3269, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4903, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6027, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3249, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4754, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4118, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2649, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4602, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1406, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4346, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5752, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5271, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4783, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3496, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4156, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4164, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1971, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1986, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2670, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7967, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6058, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.9093, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4600, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3548, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "1m 10s (- 0m 30s) (700 70%) 3.4414\n",
      "Loss tensor(15.4968, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2775, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1467, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1186, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6950, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7307, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5624, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3061, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1948, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5317, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6797, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1385, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1812, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0167, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6995, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5112, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0638, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6651, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3056, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7539, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5269, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2194, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5149, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4097, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2463, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1970, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6796, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0925, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5505, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1789, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2928, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4357, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4594, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4453, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4979, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5206, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5799, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1970, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4359, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4259, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1537, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2272, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5935, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3948, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4137, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5233, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4897, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3259, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5066, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.8951, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6824, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5430, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1596, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4477, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4123, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4156, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4919, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2579, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5585, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1643, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3290, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3395, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4799, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6160, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0921, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7095, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4361, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6154, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3836, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2841, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4740, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0161, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.8544, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3695, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5163, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.8129, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2535, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1817, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3355, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3152, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.6369, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4447, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5595, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1835, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0832, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2958, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5542, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9935, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3514, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3946, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0055, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4730, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1498, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3309, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1295, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1140, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6231, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3418, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3558, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5446, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "1m 20s (- 0m 20s) (800 80%) 3.4376\n",
      "Loss tensor(15.4812, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9948, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5128, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1915, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7226, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4672, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4415, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5490, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1331, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3538, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4295, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4002, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5229, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9951, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6297, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1666, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2622, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3614, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5850, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3269, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1670, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5228, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5880, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4804, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2997, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4272, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6055, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5450, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1004, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3949, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2940, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7157, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1141, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2758, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2716, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1000, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6506, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2512, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1813, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2449, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3527, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4681, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4009, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4374, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1842, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3392, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5500, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4247, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4392, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.9683, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3734, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3729, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5004, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5711, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3380, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3757, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1526, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.9205, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3696, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6207, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7928, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3940, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2717, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1098, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5203, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5198, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4771, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5748, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3987, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1720, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5151, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5490, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4691, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5500, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2307, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5457, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1724, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4252, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2718, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.8424, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.8332, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.8551, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9864, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5152, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2148, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5546, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3554, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3078, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3571, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1517, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4339, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5350, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5129, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1521, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5116, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3978, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3854, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4252, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5778, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2037, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "1m 29s (- 0m 9s) (900 90%) 3.4400\n",
      "Loss tensor(15.6346, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3551, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4358, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1197, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3592, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5624, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3583, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4971, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3333, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2936, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1634, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1985, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2609, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3384, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5402, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2545, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4265, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3208, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1451, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5105, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2924, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1049, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5654, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5746, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4464, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5600, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0670, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3796, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3263, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5011, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5237, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5295, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.8735, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7679, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5734, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6195, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2373, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2368, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5477, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2319, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4269, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4593, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6128, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7622, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0975, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3621, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5090, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.9666, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5842, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5528, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1391, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5207, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4291, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1913, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0860, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3953, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.7295, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6564, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6220, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3713, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3663, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4754, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0874, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7428, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2562, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2762, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4695, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4719, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3914, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4218, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3225, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6979, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4342, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6508, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2926, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5485, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2897, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4802, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4342, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1506, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.6292, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3316, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.9050, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.1767, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4151, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.9497, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5378, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.8871, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0523, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3963, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3219, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3781, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(14.8964, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2308, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.7698, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.5984, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.2663, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.3828, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.0547, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "Loss tensor(15.4624, grad_fn=<AddBackward0>)\n",
      "NLL_Plus_MAE\n",
      "1m 39s (- 0m 0s) (1000 100%) 3.4394\n",
      "Accuracy score on test set:  0.003\n",
      "Mean Absolute Error  on test set:  971.556\n"
     ]
    }
   ],
   "source": [
    "train_report(algo, input_lang, output_lang, train, X_test, y_test, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = algo.infer(input_lang, output_lang, X_test[:1000])\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain RNN with Magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magn_algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "magn_algo.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = magn_algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â Attention-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\n",
    "algo_attn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention with magnitude loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_attn_magn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "algo_attn_magn.train(input_lang, output_lang, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo_attn_magn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "tensor([[-0.2686,  0.0357, -1.1628],\n",
       "        [ 0.3468,  0.3241,  2.1244]])\n",
       "tensor([[-1.0169, -0.7126, -1.9111],\n",
       "        [-2.0660, -2.0887, -0.2884]])\n"
      ]
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/vnd.code.notebook.stderr": [
       "ipykernel_launcher:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "m = nn.LogSoftmax()\r\n",
    "input = torch.randn(2, 3)\r\n",
    "print(input)\r\n",
    "output = m(input)\r\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "output:  torch.Size([5, 4, 8, 8])\n",
       "target:  torch.Size([5, 8, 8])\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# 2D loss example (used, for example, with image inputs)\r\n",
    "N, C = 5, 4\r\n",
    "loss = nn.NLLLoss()\r\n",
    "\r\n",
    "# input is of size N x C x height x width\r\n",
    "data = torch.randn(N, 16, 10, 10)\r\n",
    "conv = nn.Conv2d(16, C, (3, 3))\r\n",
    "m = nn.LogSoftmax(dim=1)\r\n",
    "\r\n",
    "# print(data.shape)\r\n",
    "activated = m(conv(data))\r\n",
    "print(\"output: \", activated.shape)\r\n",
    "\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\r\n",
    "print(\"target: \", target.shape)\r\n",
    "output = loss(activated, target)\r\n",
    "\r\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "torch.Size([3, 5])\n",
       "torch.Size([3])\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\r\n",
    "loss = nn.NLLLoss()\r\n",
    "# input is of size N x C = 3 x 5\r\n",
    "# input = minibatchsize, number of categories\r\n",
    "\r\n",
    "input = torch.randn(3, 5, requires_grad=True)\r\n",
    "# print(input.shape)\r\n",
    "activation = m(input)\r\n",
    "print(activation.shape)\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.tensor([1, 0, 4])\r\n",
    "print(target.shape)\r\n",
    "output = loss(activation, target)\r\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 5.2e-06 s\n",
      "File: <ipython-input-10-550e04f4f4b5>\n",
      "Function: function_to_evaluate at line 4\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     4                                           def function_to_evaluate(stuff_to_evaluate):\n",
      "     5         1         52.0     52.0    100.0      pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from line_profiler import LineProfiler\r\n",
    "\r\n",
    "stuff_to_evaluate = [1,2,3]\r\n",
    "def function_to_evaluate(stuff_to_evaluate):\r\n",
    "    pass\r\n",
    "\r\n",
    "lp = LineProfiler()\r\n",
    "lp_wrapper = lp(function_to_evaluate)\r\n",
    "lp_wrapper(stuff_to_evaluate)\r\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a630840cc17be2676cbce8189d2083744dc2f6895f9cfddc5644aa2e06831cd0"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('deeplearning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}