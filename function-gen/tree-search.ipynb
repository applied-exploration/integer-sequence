{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('deeplearning': conda)"
  },
  "interpreter": {
   "hash": "a630840cc17be2676cbce8189d2083744dc2f6895f9cfddc5644aa2e06831cd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from lang import load_data_int_seq\n",
    "from utils import eq_encoder, is_eq_valid\n",
    "from typing import List\n",
    "from models.rl.env import IntegerSequenceEnv, get_current_position, encode_with_lang, decode_with_lang, eq_to_seq\n",
    "import gym, ray\n",
    "from ray.rllib.agents import ppo\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "MAX_PENALTY_MAGNITUDE = 99.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-07 16:30:39,680\tINFO worker.py:745 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4123"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequences(output_sequence: List[int], target_sequence: List[int]) -> float:\n",
    "    # print(\"output_sequence \", output_sequence)\n",
    "    # print(\"target_sequence \", output_sequence)\n",
    "    magnitude: float = 0.0\n",
    "    for x, y in zip(output_sequence, target_sequence):\n",
    "        magnitude += abs(x - y)\n",
    "    # magnitude /= len(norm_target_seq)\n",
    "    return 10 - magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate_eq(candidate: str, int_seq: List[int]) -> float:\n",
    "    if is_eq_valid(candidate) == False:\n",
    "        return -MAX_PENALTY_MAGNITUDE\n",
    "\n",
    "    output_sequence = eq_to_seq(candidate, 9)\n",
    "\n",
    "    if np.count_nonzero(output_sequence) < 1:\n",
    "        return -MAX_PENALTY_MAGNITUDE\n",
    "\n",
    "    return compare_sequences(output_sequence, int_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = IntegerSequenceEnv({\"int_sequence\": train[0][0], \"output_length\": 9, \"input_lang\": input_lang, \"output_lang\": output_lang, \"evaluate\": evaluate_candidate_eq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0, 9):\n",
    "    env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(([3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 3, 4, 5, 6, 7, 8, 9]), -99.0, True, {})"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([-1, -1, -1, -1, -1, -1, -1, -1, -1], [2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-07 16:32:52,268\tINFO trainable.py:101 -- Trainable.setup took 12.112 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-07-07 16:32:52,270\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = ppo.PPOTrainer(env=IntegerSequenceEnv, config={\n",
    "    \"env_config\": {\n",
    "        \"int_sequence\": train[0][0],\n",
    "        \"output_length\": 9,\n",
    "        \"input_lang\": input_lang,\n",
    "        \"output_lang\": output_lang,\n",
    "        \"evaluate\": evaluate_candidate_eq\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-07 16:32:59,111\tWARNING ppo.py:237 -- The magnitude of your environment rewards are more than 17727.0x the scale of `vf_clip_param`. This means that it will take more than 17727.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'episode_reward_max': -62.0,\n",
       " 'episode_reward_min': -76372038.0,\n",
       " 'episode_reward_mean': -177266.36036036036,\n",
       " 'episode_len_mean': 9.0,\n",
       " 'episode_media': {},\n",
       " 'episodes_this_iter': 444,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [-99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -1534.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -7238.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -2092046.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -64710.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -62.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -52074.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -73398.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -99.0,\n",
       "   -76372038.0],\n",
       "  'episode_lengths': [9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9,\n",
       "   9]},\n",
       " 'sampler_perf': {'mean_raw_obs_processing_ms': 0.16258461126263649,\n",
       "  'mean_inference_ms': 0.7768893825715928,\n",
       "  'mean_action_processing_ms': 0.06217589561847493,\n",
       "  'mean_env_wait_ms': 0.31385536136655795,\n",
       "  'mean_env_render_ms': 0.0},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 2,\n",
       " 'timesteps_total': 4000,\n",
       " 'agent_timesteps_total': 4000,\n",
       " 'timers': {'sample_time_ms': 2797.17,\n",
       "  'sample_throughput': 1430.017,\n",
       "  'load_time_ms': 39.591,\n",
       "  'load_throughput': 101033.483,\n",
       "  'learn_time_ms': 3096.048,\n",
       "  'learn_throughput': 1291.97,\n",
       "  'update_time_ms': 2.31},\n",
       " 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 0.20000000298023224,\n",
       "     'cur_lr': 4.999999873689376e-05,\n",
       "     'total_loss': 12232982000000.0,\n",
       "     'policy_loss': -0.014233499,\n",
       "     'vf_loss': 12232982000000.0,\n",
       "     'vf_explained_var': -0.00038756285,\n",
       "     'kl': 0.004065979,\n",
       "     'entropy': 2.6351361,\n",
       "     'entropy_coeff': 0.0,\n",
       "     'model': {}}}},\n",
       "  'num_steps_sampled': 4000,\n",
       "  'num_agent_steps_sampled': 4000,\n",
       "  'num_steps_trained': 4000,\n",
       "  'num_agent_steps_trained': 4000},\n",
       " 'done': False,\n",
       " 'episodes_total': 444,\n",
       " 'training_iteration': 1,\n",
       " 'experiment_id': '0cd9d2ad178e4059a75e95c4e51a5d77',\n",
       " 'date': '2021-07-07_16-32-59',\n",
       " 'timestamp': 1625668379,\n",
       " 'time_this_iter_s': 6.69109582901001,\n",
       " 'time_total_s': 6.69109582901001,\n",
       " 'pid': 92434,\n",
       " 'hostname': 'marks-MBP.local',\n",
       " 'node_ip': '10.240.179.210',\n",
       " 'config': {'num_workers': 2,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'create_env_on_driver': False,\n",
       "  'rollout_fragment_length': 200,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'_use_default_native_models': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'num_framestacks': 'auto',\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   'framestack': True},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'IntegerSequenceEnv',\n",
       "  'env_config': {'int_sequence': array([ 4,  8, 12, 16, 20, 24, 28, 32]),\n",
       "   'output_length': 9,\n",
       "   'input_lang': <lang.Lang at 0x1f0837640>,\n",
       "   'output_lang': <lang.Lang at 0x1f0837520>,\n",
       "   'evaluate': <function __main__.evaluate_candidate_eq(candidate: str, int_seq: List[int]) -> float>},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'tf',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {},\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent',\n",
       "   'count_steps_by': 'env_steps'},\n",
       "  'logger_config': None,\n",
       "  'simple_optimizer': False,\n",
       "  'monitor': -1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 30,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'vf_share_layers': -1},\n",
       " 'time_since_restore': 6.69109582901001,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': 30.77, 'ram_util_percent': 70.41}}"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}