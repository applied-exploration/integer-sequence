{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  },
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from models.rnn.encoder_decoder_gru import EncoderRNN, DecoderRNN\n",
    "from models.rnn.combined_networks import train\n",
    "from rnn_utils import tensorsFromPair\n",
    "from utils import showPlot, timeSince, asMinutes\n",
    "from lang import load_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Training Loops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.Tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]) # -> binary encoded integer sequence\n",
    "target_seq = torch.Tensor([0, 2, 5, 6]) # -> character encoded function\n",
    "\n",
    "training_pairs = [[input_seq, target_seq]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq, seq, pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('24,28,32,36,40,44,48,52', '4*t+4+2*8'), ('36,37,38,39,40,41,42,43', '0+5*8-5+t')]\n24,28,32,36,40,44,48,52\n4*t+4+2*8\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:2])\n",
    "print(pairs[0][0])\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eq_to_seq\n",
    "def converted_loss(decoder_output, target):\n",
    "    print(decoder_output)\n",
    "    print(target)\n",
    "    \n",
    "    decoded_words = []\n",
    "    # output_lang.index2word[topi.item()]\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    \n",
    "    print(eq.index2word[topi.item()])\n",
    "\n",
    "\n",
    "\n",
    "    # output = eq_to_seq(self.decoded_representation, len(self.param[\"target_sequence\"])) \n",
    "\n",
    "    # fitness: float = 0.0\n",
    "    \n",
    "    # for i, value in enumerate(target_sequence):\n",
    "    #     fitness -= min(1000, (value - output[i])**2)\n",
    "\n",
    "    # fitness /= len(target_sequence)\n",
    "\n",
    "    #fitness += 0.0 # eg.: closeness to actual target value\n",
    "    #fitness -= 0.0 # eg.: number of symbols\n",
    "\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), seq, eq)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion =nn.NLLLoss() #  converted_loss\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 15s (- 132m 58s) (100 0%) 2.1639\n",
      "0m 20s (- 85m 49s) (200 0%) 1.7180\n",
      "0m 25s (- 70m 39s) (300 0%) 1.6271\n",
      "0m 30s (- 62m 4s) (400 0%) 1.5830\n",
      "0m 34s (- 56m 38s) (500 1%) 1.6162\n",
      "0m 38s (- 53m 2s) (600 1%) 1.6321\n",
      "0m 42s (- 50m 16s) (700 1%) 1.6138\n",
      "0m 46s (- 47m 48s) (800 1%) 1.6033\n",
      "0m 50s (- 46m 3s) (900 1%) 1.5938\n",
      "0m 54s (- 44m 48s) (1000 2%) 1.6080\n",
      "0m 59s (- 43m 47s) (1100 2%) 1.5745\n",
      "1m 2s (- 42m 36s) (1200 2%) 1.5847\n",
      "1m 6s (- 41m 41s) (1300 2%) 1.5592\n",
      "1m 11s (- 41m 22s) (1400 2%) 1.5360\n",
      "1m 19s (- 42m 58s) (1500 3%) 1.5201\n",
      "1m 24s (- 42m 40s) (1600 3%) 1.5515\n",
      "1m 28s (- 41m 58s) (1700 3%) 1.5224\n",
      "1m 32s (- 41m 15s) (1800 3%) 1.5144\n",
      "1m 36s (- 40m 39s) (1900 3%) 1.5547\n",
      "1m 40s (- 40m 6s) (2000 4%) 1.5098\n",
      "1m 45s (- 40m 0s) (2100 4%) 1.5050\n",
      "1m 52s (- 40m 51s) (2200 4%) 1.5203\n",
      "1m 57s (- 40m 42s) (2300 4%) 1.5047\n",
      "2m 1s (- 40m 17s) (2400 4%) 1.5273\n",
      "2m 8s (- 40m 43s) (2500 5%) 1.4977\n",
      "2m 14s (- 40m 44s) (2600 5%) 1.4976\n",
      "2m 18s (- 40m 26s) (2700 5%) 1.5360\n",
      "2m 22s (- 40m 0s) (2800 5%) 1.5028\n",
      "2m 26s (- 39m 40s) (2900 5%) 1.5091\n",
      "2m 30s (- 39m 17s) (3000 6%) 1.5319\n",
      "2m 34s (- 38m 53s) (3100 6%) 1.5020\n",
      "2m 38s (- 38m 32s) (3200 6%) 1.4997\n",
      "2m 41s (- 38m 10s) (3300 6%) 1.5095\n",
      "2m 45s (- 37m 52s) (3400 6%) 1.5397\n",
      "2m 49s (- 37m 35s) (3500 7%) 1.5131\n",
      "2m 53s (- 37m 16s) (3600 7%) 1.4838\n",
      "2m 57s (- 37m 2s) (3700 7%) 1.5185\n",
      "3m 2s (- 36m 56s) (3800 7%) 1.4993\n",
      "3m 6s (- 36m 41s) (3900 7%) 1.4724\n",
      "3m 10s (- 36m 25s) (4000 8%) 1.4694\n",
      "3m 13s (- 36m 7s) (4100 8%) 1.4634\n",
      "3m 17s (- 35m 50s) (4200 8%) 1.4794\n",
      "3m 20s (- 35m 34s) (4300 8%) 1.4768\n",
      "3m 24s (- 35m 17s) (4400 8%) 1.4867\n",
      "3m 27s (- 35m 1s) (4500 9%) 1.5291\n",
      "3m 31s (- 34m 46s) (4600 9%) 1.4356\n",
      "3m 34s (- 34m 32s) (4700 9%) 1.4714\n",
      "3m 38s (- 34m 18s) (4800 9%) 1.4721\n",
      "3m 42s (- 34m 4s) (4900 9%) 1.5296\n",
      "3m 45s (- 33m 51s) (5000 10%) 1.5130\n",
      "3m 49s (- 33m 38s) (5100 10%) 1.4908\n",
      "3m 52s (- 33m 26s) (5200 10%) 1.4533\n",
      "3m 56s (- 33m 14s) (5300 10%) 1.4459\n",
      "4m 0s (- 33m 2s) (5400 10%) 1.5171\n",
      "4m 3s (- 32m 50s) (5500 11%) 1.4448\n",
      "4m 7s (- 32m 41s) (5600 11%) 1.4931\n",
      "4m 10s (- 32m 29s) (5700 11%) 1.4916\n",
      "4m 14s (- 32m 18s) (5800 11%) 1.4797\n",
      "4m 17s (- 32m 8s) (5900 11%) 1.4838\n",
      "4m 21s (- 31m 57s) (6000 12%) 1.5005\n",
      "4m 25s (- 31m 50s) (6100 12%) 1.4500\n",
      "4m 29s (- 31m 43s) (6200 12%) 1.4831\n",
      "4m 33s (- 31m 35s) (6300 12%) 1.4640\n",
      "4m 37s (- 31m 28s) (6400 12%) 1.4505\n",
      "4m 40s (- 31m 20s) (6500 13%) 1.4601\n",
      "4m 44s (- 31m 11s) (6600 13%) 1.4907\n",
      "4m 48s (- 31m 3s) (6700 13%) 1.4929\n",
      "4m 52s (- 30m 55s) (6800 13%) 1.4851\n",
      "4m 55s (- 30m 46s) (6900 13%) 1.4531\n",
      "4m 59s (- 30m 38s) (7000 14%) 1.4676\n",
      "5m 2s (- 30m 30s) (7100 14%) 1.4468\n",
      "5m 6s (- 30m 22s) (7200 14%) 1.4845\n",
      "5m 10s (- 30m 14s) (7300 14%) 1.4821\n",
      "5m 13s (- 30m 6s) (7400 14%) 1.4417\n",
      "5m 17s (- 29m 58s) (7500 15%) 1.4817\n",
      "5m 20s (- 29m 50s) (7600 15%) 1.4765\n",
      "5m 24s (- 29m 43s) (7700 15%) 1.4485\n",
      "5m 28s (- 29m 36s) (7800 15%) 1.4573\n",
      "5m 31s (- 29m 28s) (7900 15%) 1.4616\n",
      "5m 35s (- 29m 21s) (8000 16%) 1.4934\n",
      "5m 39s (- 29m 14s) (8100 16%) 1.4932\n",
      "5m 42s (- 29m 7s) (8200 16%) 1.4258\n",
      "5m 46s (- 29m 0s) (8300 16%) 1.4695\n",
      "5m 49s (- 28m 53s) (8400 16%) 1.4490\n",
      "5m 53s (- 28m 46s) (8500 17%) 1.4670\n",
      "5m 57s (- 28m 39s) (8600 17%) 1.4612\n",
      "6m 0s (- 28m 32s) (8700 17%) 1.4593\n",
      "6m 4s (- 28m 26s) (8800 17%) 1.4868\n",
      "6m 7s (- 28m 19s) (8900 17%) 1.4315\n",
      "6m 11s (- 28m 13s) (9000 18%) 1.4755\n",
      "6m 15s (- 28m 6s) (9100 18%) 1.4767\n",
      "6m 18s (- 28m 0s) (9200 18%) 1.4620\n",
      "6m 22s (- 27m 54s) (9300 18%) 1.4618\n",
      "6m 26s (- 27m 47s) (9400 18%) 1.4399\n",
      "6m 29s (- 27m 41s) (9500 19%) 1.4499\n",
      "6m 33s (- 27m 35s) (9600 19%) 1.4445\n",
      "6m 36s (- 27m 29s) (9700 19%) 1.4722\n",
      "6m 40s (- 27m 23s) (9800 19%) 1.4498\n",
      "6m 44s (- 27m 17s) (9900 19%) 1.4547\n",
      "6m 47s (- 27m 11s) (10000 20%) 1.4785\n",
      "6m 51s (- 27m 6s) (10100 20%) 1.4436\n",
      "6m 55s (- 27m 1s) (10200 20%) 1.4496\n",
      "6m 59s (- 26m 55s) (10300 20%) 1.4665\n",
      "7m 2s (- 26m 50s) (10400 20%) 1.4681\n",
      "7m 6s (- 26m 45s) (10500 21%) 1.4559\n",
      "7m 10s (- 26m 39s) (10600 21%) 1.4821\n",
      "7m 14s (- 26m 34s) (10700 21%) 1.4344\n",
      "7m 18s (- 26m 29s) (10800 21%) 1.4562\n",
      "7m 21s (- 26m 24s) (10900 21%) 1.4368\n",
      "7m 25s (- 26m 18s) (11000 22%) 1.4573\n",
      "7m 28s (- 26m 13s) (11100 22%) 1.4753\n",
      "7m 32s (- 26m 7s) (11200 22%) 1.4539\n",
      "7m 36s (- 26m 2s) (11300 22%) 1.4514\n",
      "7m 40s (- 25m 57s) (11400 22%) 1.5018\n",
      "7m 43s (- 25m 52s) (11500 23%) 1.4426\n",
      "7m 47s (- 25m 47s) (11600 23%) 1.4691\n",
      "7m 51s (- 25m 42s) (11700 23%) 1.4000\n",
      "7m 54s (- 25m 37s) (11800 23%) 1.4628\n",
      "7m 58s (- 25m 32s) (11900 23%) 1.4438\n",
      "8m 2s (- 25m 27s) (12000 24%) 1.4574\n",
      "8m 6s (- 25m 23s) (12100 24%) 1.4396\n",
      "8m 10s (- 25m 21s) (12200 24%) 1.4326\n",
      "8m 14s (- 25m 15s) (12300 24%) 1.4746\n",
      "8m 18s (- 25m 10s) (12400 24%) 1.4258\n",
      "8m 22s (- 25m 6s) (12500 25%) 1.4693\n",
      "8m 26s (- 25m 2s) (12600 25%) 1.4315\n",
      "8m 29s (- 24m 57s) (12700 25%) 1.4551\n",
      "8m 33s (- 24m 51s) (12800 25%) 1.4630\n",
      "8m 36s (- 24m 46s) (12900 25%) 1.4469\n",
      "8m 40s (- 24m 40s) (13000 26%) 1.4069\n",
      "8m 43s (- 24m 34s) (13100 26%) 1.4132\n",
      "8m 46s (- 24m 28s) (13200 26%) 1.4284\n",
      "8m 50s (- 24m 23s) (13300 26%) 1.4775\n",
      "8m 53s (- 24m 18s) (13400 26%) 1.4017\n",
      "8m 57s (- 24m 12s) (13500 27%) 1.4119\n",
      "9m 0s (- 24m 6s) (13600 27%) 1.4084\n",
      "9m 3s (- 24m 0s) (13700 27%) 1.4503\n",
      "9m 7s (- 23m 55s) (13800 27%) 1.4711\n",
      "9m 11s (- 23m 51s) (13900 27%) 1.4049\n",
      "9m 14s (- 23m 46s) (14000 28%) 1.4036\n",
      "9m 17s (- 23m 40s) (14100 28%) 1.4282\n",
      "9m 21s (- 23m 35s) (14200 28%) 1.4302\n",
      "9m 25s (- 23m 31s) (14300 28%) 1.4607\n",
      "9m 29s (- 23m 27s) (14400 28%) 1.4284\n",
      "9m 33s (- 23m 22s) (14500 28%) 1.4070\n",
      "9m 36s (- 23m 17s) (14600 29%) 1.4269\n",
      "9m 39s (- 23m 12s) (14700 29%) 1.4361\n",
      "9m 43s (- 23m 6s) (14800 29%) 1.4084\n",
      "9m 46s (- 23m 1s) (14900 29%) 1.3817\n",
      "9m 49s (- 22m 56s) (15000 30%) 1.4445\n",
      "9m 53s (- 22m 51s) (15100 30%) 1.4328\n",
      "9m 56s (- 22m 45s) (15200 30%) 1.4319\n",
      "9m 59s (- 22m 40s) (15300 30%) 1.4359\n",
      "10m 3s (- 22m 35s) (15400 30%) 1.4416\n",
      "10m 6s (- 22m 30s) (15500 31%) 1.4683\n",
      "10m 10s (- 22m 25s) (15600 31%) 1.4562\n",
      "10m 13s (- 22m 20s) (15700 31%) 1.3727\n",
      "10m 16s (- 22m 15s) (15800 31%) 1.4560\n",
      "10m 20s (- 22m 11s) (15900 31%) 1.4501\n",
      "10m 25s (- 22m 8s) (16000 32%) 1.4031\n",
      "10m 29s (- 22m 5s) (16100 32%) 1.4445\n",
      "10m 33s (- 22m 2s) (16200 32%) 1.4126\n",
      "10m 37s (- 21m 57s) (16300 32%) 1.4331\n",
      "10m 40s (- 21m 52s) (16400 32%) 1.4197\n",
      "10m 43s (- 21m 47s) (16500 33%) 1.4568\n",
      "10m 47s (- 21m 42s) (16600 33%) 1.4498\n",
      "10m 50s (- 21m 37s) (16700 33%) 1.4187\n",
      "10m 53s (- 21m 32s) (16800 33%) 1.4059\n",
      "10m 57s (- 21m 27s) (16900 33%) 1.4066\n",
      "11m 0s (- 21m 22s) (17000 34%) 1.4136\n",
      "11m 3s (- 21m 17s) (17100 34%) 1.4438\n",
      "11m 7s (- 21m 12s) (17200 34%) 1.4345\n",
      "11m 10s (- 21m 7s) (17300 34%) 1.4411\n",
      "11m 13s (- 21m 2s) (17400 34%) 1.4529\n",
      "11m 17s (- 20m 57s) (17500 35%) 1.4265\n",
      "11m 20s (- 20m 52s) (17600 35%) 1.4326\n",
      "11m 23s (- 20m 47s) (17700 35%) 1.4398\n",
      "11m 27s (- 20m 42s) (17800 35%) 1.4430\n",
      "11m 30s (- 20m 38s) (17900 35%) 1.4359\n",
      "11m 33s (- 20m 33s) (18000 36%) 1.4196\n",
      "11m 37s (- 20m 28s) (18100 36%) 1.4377\n",
      "11m 40s (- 20m 23s) (18200 36%) 1.4196\n",
      "11m 43s (- 20m 19s) (18300 36%) 1.4147\n",
      "11m 47s (- 20m 14s) (18400 36%) 1.4109\n",
      "11m 50s (- 20m 10s) (18500 37%) 1.4113\n",
      "11m 54s (- 20m 6s) (18600 37%) 1.4295\n",
      "11m 58s (- 20m 2s) (18700 37%) 1.4241\n",
      "12m 1s (- 19m 57s) (18800 37%) 1.4425\n",
      "12m 5s (- 19m 53s) (18900 37%) 1.4336\n",
      "12m 8s (- 19m 49s) (19000 38%) 1.4375\n",
      "12m 12s (- 19m 45s) (19100 38%) 1.4315\n",
      "12m 16s (- 19m 40s) (19200 38%) 1.4167\n",
      "12m 19s (- 19m 36s) (19300 38%) 1.4483\n",
      "12m 23s (- 19m 32s) (19400 38%) 1.4140\n",
      "12m 26s (- 19m 28s) (19500 39%) 1.3955\n",
      "12m 30s (- 19m 23s) (19600 39%) 1.4176\n",
      "12m 33s (- 19m 19s) (19700 39%) 1.4229\n",
      "12m 37s (- 19m 15s) (19800 39%) 1.4102\n",
      "12m 41s (- 19m 11s) (19900 39%) 1.4440\n",
      "12m 44s (- 19m 6s) (20000 40%) 1.4288\n",
      "12m 49s (- 19m 4s) (20100 40%) 1.4524\n",
      "12m 53s (- 19m 0s) (20200 40%) 1.4038\n",
      "12m 57s (- 18m 57s) (20300 40%) 1.3981\n",
      "13m 1s (- 18m 54s) (20400 40%) 1.3914\n",
      "13m 5s (- 18m 50s) (20500 41%) 1.3992\n",
      "13m 9s (- 18m 46s) (20600 41%) 1.4493\n",
      "13m 13s (- 18m 42s) (20700 41%) 1.3943\n",
      "13m 17s (- 18m 39s) (20800 41%) 1.4452\n",
      "13m 21s (- 18m 36s) (20900 41%) 1.4117\n",
      "13m 25s (- 18m 32s) (21000 42%) 1.4206\n",
      "13m 29s (- 18m 29s) (21100 42%) 1.4350\n",
      "13m 34s (- 18m 26s) (21200 42%) 1.4297\n",
      "13m 38s (- 18m 23s) (21300 42%) 1.5232\n",
      "13m 42s (- 18m 19s) (21400 42%) 1.4342\n",
      "13m 47s (- 18m 16s) (21500 43%) 1.3737\n",
      "13m 51s (- 18m 12s) (21600 43%) 1.4184\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b9912fb3e61e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-f357b39de05a>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[1;32m---> 19\u001b[1;33m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\models\\rnn\\combined_networks.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(seq.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, eq.n_words).to(device)\n",
    "\n",
    "training(encoder, decoder, 50000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_utils import tensorFromSentence\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "input_lang = seq\n",
    "output_lang = eq\n",
    "EOS_token = 0\n",
    "SOS_token = 1\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)  # this if or simply decoder\n",
    "                \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> 4,5,6,7,8,9,10,11\n= 3-2*6*0+t\n< t + t - t + 1 * 1 <EOS>\n\n> -2,-7,-12,-17,-22,-27,-32,-37\n= t+2+1-t*6\n< t - t * t * t * t <EOS>\n\n> -6,-5,-4,-3,-2,-1,0,1\n= 1-5-8+t+5\n< t - t - t - t - t <EOS>\n\n> 11,13,15,17,19,21,23,25\n= t*2+9-t+t\n< t + t + t + t + t <EOS>\n\n> -1,0,1,2,3,4,5,6\n= t+8+4-7-7\n< t - t - t - t - t <EOS>\n\n> 6,7,8,9,10,11,12,13\n= 7+0+6+t-8\n< t + 1 - t + 1 * 1 <EOS>\n\n> 16,20,24,28,32,36,40,44\n= 9+5+t*4-2\n< t + 4 * 4 + 4 + t <EOS>\n\n> 3,12,27,48,75,108,147,192\n= t*3*t+5*0\n< t * t * t * t * t <EOS>\n\n> 0,-7,-14,-21,-28,-35,-42,-49\n= 2-t-t*6+5\n< 7 - t * t * t * t <EOS>\n\n> 4,8,12,16,20,24,28,32\n= t*3+0*7+t\n< t * t - t * t - t <EOS>\n\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}