{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  },
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from models.rnn.encoder_decoder_gru import EncoderRNN, DecoderRNN\n",
    "from models.rnn.combined_networks import train\n",
    "from rnn_utils import tensorsFromPair\n",
    "from utils import showPlot, timeSince, asMinutes\n",
    "from lang import load_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "source": [
    "# Training Loops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.Tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]) # -> binary encoded integer sequence\n",
    "target_seq = torch.Tensor([0, 2, 5, 6]) # -> character encoded function\n",
    "\n",
    "training_pairs = [[input_seq, target_seq]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq, seq, pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('24,28,32,36,40,44,48,52', '4*t+4+2*8'), ('36,37,38,39,40,41,42,43', '0+5*8-5+t')]\n24,28,32,36,40,44,48,52\n4*t+4+2*8\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:2])\n",
    "print(pairs[0][0])\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequences(output_sequence, target_sequence):\n",
    "        magnitude: float = 0.0\n",
    "        \n",
    "        for i, value in enumerate(target_sequence):\n",
    "            magnitude +=  min(1000,value - output_sequence[i])**2\n",
    "\n",
    "        magnitude /= len(target_sequence)\n",
    "\n",
    "        return torch.tensor(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eq_to_seq, is_eq_valid\n",
    "\n",
    "def calc_magnitude(decoder_outputs, target_outputs):\n",
    "    max_penalty_magnitude = torch.tensor(10000000000)\n",
    "  \n",
    "    decoded_output_symbols = []\n",
    "    decoded_target_symbols = []\n",
    "    detached_target_outputs = target_outputs.cpu().detach().numpy().squeeze()\n",
    "\n",
    "    for decoder_output in decoder_outputs:\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        decoded_output = eq.index2word[topi.item()]\n",
    "        decoded_output_symbols.append(decoded_output)\n",
    "    \n",
    "    # if any(i in [0, 1] for i in decoder_outputs):\n",
    "    #     print(\"Equation not valid 1\")\n",
    "    #     return max_penalty_magnitude\n",
    "\n",
    "    for i, target_output in enumerate(detached_target_outputs):\n",
    "        decoded_target = eq.index2word[target_output]\n",
    "        decoded_target_symbols.append(decoded_target)\n",
    "    \n",
    "    stringified_output = ''.join(decoded_output_symbols)\n",
    "    \n",
    "    # print(\"--- Target ---\")\n",
    "    # print(detached_target_outputs)\n",
    "    # print(decoded_target_symbols) \n",
    "\n",
    "    # print(\"--- Output ---\")\n",
    "    # print(decoder_outputs[0]) \n",
    "    # print(decoded_output_symbols) \n",
    "    # print(stringified_output)\n",
    "\n",
    "    if is_eq_valid(stringified_output) == False:\n",
    "        # print(\"Equation not valid 2\")\n",
    "        return max_penalty_magnitude\n",
    "\n",
    "    output_sequence = eq_to_seq(stringified_output, 9)\n",
    "\n",
    "    # if np.zeros(9) == np.array(output_sequence):\n",
    "    #     print(\"Equation not valid 3\")\n",
    "    #     return max_penalty_magnitude\n",
    "    # else:\n",
    "    stringified_target = ''.join(decoded_target_symbols)\n",
    "    target_sequence = eq_to_seq(stringified_target, 9)\n",
    "    \n",
    "    return compare_sequences(output_sequence, target_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), seq, eq)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion =nn.NLLLoss() #  converted_loss\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, calc_magnitude)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            # enablePrint()\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            # blockPrint()\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 0s (- 0m 22s) (1 1%) 0.0000\n",
      "0m 0s (- 0m 15s) (2 2%) 27461566464.0000\n",
      "0m 0s (- 0m 13s) (3 3%) 8640042415510309888.0000\n",
      "0m 0s (- 0m 12s) (4 4%) 378285592790509682688.0000\n",
      "0m 0s (- 0m 13s) (5 5%) 298176885551233892352.0000\n",
      "0m 0s (- 0m 12s) (6 6%) 1155148984982544449536.0000\n",
      "0m 0s (- 0m 12s) (7 7%) 1289556776651593875456.0000\n",
      "0m 1s (- 0m 12s) (8 8%) 1191237905056533839872.0000\n",
      "0m 1s (- 0m 11s) (9 9%) 823083778872742772736.0000\n",
      "0m 1s (- 0m 11s) (10 10%) 1032396171379157762048.0000\n",
      "0m 1s (- 0m 11s) (11 11%) 685467228764187131904.0000\n",
      "0m 1s (- 0m 10s) (12 12%) 890993163588895113216.0000\n",
      "0m 1s (- 0m 10s) (13 13%) 673504936318951751680.0000\n",
      "0m 1s (- 0m 10s) (14 14%) 1363991145392866590720.0000\n",
      "0m 2s (- 0m 11s) (15 15%) 1140027586283694587904.0000\n",
      "0m 2s (- 0m 11s) (16 16%) 793156627513926352896.0000\n",
      "0m 2s (- 0m 10s) (17 17%) 819376246774505406464.0000\n",
      "0m 2s (- 0m 10s) (18 18%) 984892315099644428288.0000\n",
      "0m 2s (- 0m 10s) (19 19%) 1135727098999518527488.0000\n",
      "0m 2s (- 0m 10s) (20 20%) 380898468704319373312.0000\n",
      "0m 2s (- 0m 10s) (21 21%) 199843123929905790976.0000\n",
      "0m 2s (- 0m 9s) (22 22%) 0.0000\n",
      "0m 2s (- 0m 9s) (23 23%) 326071646840710955008.0000\n",
      "0m 2s (- 0m 9s) (24 24%) 1262340285613496336384.0000\n",
      "0m 3s (- 0m 9s) (25 25%) 938509798832351084544.0000\n",
      "0m 3s (- 0m 9s) (26 26%) 46195310778720346112.0000\n",
      "0m 3s (- 0m 8s) (27 27%) 142873390847352635392.0000\n",
      "0m 3s (- 0m 8s) (28 28%) 834938097516912050176.0000\n",
      "0m 3s (- 0m 8s) (29 28%) 701674332743205388288.0000\n",
      "0m 3s (- 0m 8s) (30 30%) 1061335852224677806080.0000\n",
      "0m 3s (- 0m 8s) (31 31%) 83000918919973175296.0000\n",
      "0m 3s (- 0m 7s) (32 32%) 74512119166714609664.0000\n",
      "0m 3s (- 0m 7s) (33 33%) 708359476030074126336.0000\n",
      "0m 3s (- 0m 7s) (34 34%) 884934245830212190208.0000\n",
      "0m 4s (- 0m 7s) (35 35%) 476055982245951438848.0000\n",
      "0m 4s (- 0m 7s) (36 36%) 0.0000\n",
      "0m 4s (- 0m 7s) (37 37%) 963302171076020928512.0000\n",
      "0m 4s (- 0m 7s) (38 38%) 1087611766480598990848.0000\n",
      "0m 4s (- 0m 7s) (39 39%) 1087214211223492755456.0000\n",
      "0m 4s (- 0m 7s) (40 40%) 1057733422882744172544.0000\n",
      "0m 5s (- 0m 7s) (41 41%) 1489737726848547684352.0000\n",
      "0m 5s (- 0m 7s) (42 42%) 540055398060615991296.0000\n",
      "0m 5s (- 0m 7s) (43 43%) 322211414567607992320.0000\n",
      "0m 5s (- 0m 7s) (44 44%) 585269624289574125568.0000\n",
      "0m 5s (- 0m 7s) (45 45%) 856117682139505360896.0000\n",
      "0m 5s (- 0m 6s) (46 46%) 614056182747763572736.0000\n",
      "0m 5s (- 0m 6s) (47 47%) 222630676578205237248.0000\n",
      "0m 6s (- 0m 6s) (48 48%) 674106110574210318336.0000\n",
      "0m 6s (- 0m 6s) (49 49%) 223355516864481656832.0000\n",
      "0m 6s (- 0m 6s) (50 50%) 375049615720755625984.0000\n",
      "0m 6s (- 0m 6s) (51 51%) 770746772063126159360.0000\n",
      "0m 6s (- 0m 6s) (52 52%) 631888692127295209472.0000\n",
      "0m 6s (- 0m 6s) (53 53%) 574621819985577443328.0000\n",
      "0m 7s (- 0m 6s) (54 54%) 675315833729117323264.0000\n",
      "0m 7s (- 0m 5s) (55 55%) 1098340128922930249728.0000\n",
      "0m 7s (- 0m 5s) (56 56%) 590375355187124109312.0000\n",
      "0m 7s (- 0m 5s) (57 56%) 570686180566213722112.0000\n",
      "0m 7s (- 0m 5s) (58 57%) 745583866160114302976.0000\n",
      "0m 7s (- 0m 5s) (59 59%) 402305456960597262336.0000\n",
      "0m 7s (- 0m 5s) (60 60%) 886454379589435785216.0000\n",
      "0m 8s (- 0m 5s) (61 61%) 236824263385072599040.0000\n",
      "0m 8s (- 0m 4s) (62 62%) 132926557751607296000.0000\n",
      "0m 8s (- 0m 4s) (63 63%) 266441454499535192064.0000\n",
      "0m 8s (- 0m 4s) (64 64%) 204107737228300091392.0000\n",
      "0m 8s (- 0m 4s) (65 65%) 489653588010880466944.0000\n",
      "0m 8s (- 0m 4s) (66 66%) 631657544876420366336.0000\n",
      "0m 8s (- 0m 4s) (67 67%) 1038161792212108181504.0000\n",
      "0m 8s (- 0m 4s) (68 68%) 93559460471980523520.0000\n",
      "0m 8s (- 0m 3s) (69 69%) 429580157023878447104.0000\n",
      "0m 8s (- 0m 3s) (70 70%) 716444450671120351232.0000\n",
      "0m 8s (- 0m 3s) (71 71%) 485889254262342811648.0000\n",
      "0m 8s (- 0m 3s) (72 72%) 82024383709522067456.0000\n",
      "0m 9s (- 0m 3s) (73 73%) 268224204412029829120.0000\n",
      "0m 9s (- 0m 3s) (74 74%) 101742775433015017472.0000\n",
      "0m 9s (- 0m 3s) (75 75%) 487487750655082627072.0000\n",
      "0m 9s (- 0m 2s) (76 76%) 620228140857093521408.0000\n",
      "0m 9s (- 0m 2s) (77 77%) 398252526918438158336.0000\n",
      "0m 9s (- 0m 2s) (78 78%) 0.0000\n",
      "0m 9s (- 0m 2s) (79 79%) 452809273541892702208.0000\n",
      "0m 9s (- 0m 2s) (80 80%) 756856376027422654464.0000\n",
      "0m 10s (- 0m 2s) (81 81%) 1169524474993111072768.0000\n",
      "0m 10s (- 0m 2s) (82 82%) 767913613832542748672.0000\n",
      "0m 10s (- 0m 2s) (83 83%) 476523005527309746176.0000\n",
      "0m 10s (- 0m 2s) (84 84%) 519553098526983847936.0000\n",
      "0m 10s (- 0m 1s) (85 85%) 738866240660933181440.0000\n",
      "0m 10s (- 0m 1s) (86 86%) 362184379697730027520.0000\n",
      "0m 10s (- 0m 1s) (87 87%) 966155876979904348160.0000\n",
      "0m 11s (- 0m 1s) (88 88%) 1102494586989188874240.0000\n",
      "0m 11s (- 0m 1s) (89 89%) 544984250082800959488.0000\n",
      "0m 11s (- 0m 1s) (90 90%) 777992669798597918720.0000\n",
      "0m 11s (- 0m 1s) (91 91%) 533681566097989238784.0000\n",
      "0m 11s (- 0m 1s) (92 92%) 0.0000\n",
      "0m 11s (- 0m 0s) (93 93%) 1014825490022962429952.0000\n",
      "0m 11s (- 0m 0s) (94 94%) 891967573663272009728.0000\n",
      "0m 12s (- 0m 0s) (95 95%) 814147173542160760832.0000\n",
      "0m 12s (- 0m 0s) (96 96%) 464206730151362953216.0000\n",
      "0m 12s (- 0m 0s) (97 97%) 582616047094132113408.0000\n",
      "0m 12s (- 0m 0s) (98 98%) 485996777703446282240.0000\n",
      "0m 12s (- 0m 0s) (99 99%) 874152459437301170176.0000\n",
      "0m 12s (- 0m 0s) (100 100%) 516768297697399341056.0000\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(seq.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, eq.n_words).to(device)\n",
    "\n",
    "\n",
    "# blockPrint()\n",
    "training(encoder, decoder, 100, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_utils import tensorFromSentence\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "input_lang = seq\n",
    "output_lang = eq\n",
    "EOS_token = 0\n",
    "SOS_token = 1\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)  # this if or simply decoder\n",
    "                \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}