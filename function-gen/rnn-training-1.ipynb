{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  },
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from models.rnn.encoder_decoder_gru import EncoderRNN, DecoderRNN\n",
    "from models.rnn.combined_networks import train\n",
    "from rnn_utils import tensorsFromPair\n",
    "from utils import showPlot, timeSince, asMinutes\n",
    "from lang import load_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "source": [
    "# Training Loops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.Tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]) # -> binary encoded integer sequence\n",
    "target_seq = torch.Tensor([0, 2, 5, 6]) # -> character encoded function\n",
    "\n",
    "training_pairs = [[input_seq, target_seq]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq, seq, pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('24,28,32,36,40,44,48,52', '4*t+4+2*8'), ('36,37,38,39,40,41,42,43', '0+5*8-5+t')]\n24,28,32,36,40,44,48,52\n4*t+4+2*8\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:2])\n",
    "print(pairs[0][0])\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequences(output_sequence, target_sequence):\n",
    "        magnitude: float = 0.0\n",
    "\n",
    "        # print(output_sequence)\n",
    "        # print(target_sequence)\n",
    "        \n",
    "        for i, value in enumerate(target_sequence):\n",
    "            magnitude +=  min(5, abs(value - output_sequence[i]))#**2\n",
    "\n",
    "        magnitude /= len(target_sequence)\n",
    "\n",
    "        \n",
    "        magnitude = min(8, magnitude)\n",
    "        print(magnitude)\n",
    "\n",
    "        return torch.tensor(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eq_to_seq, is_eq_valid\n",
    "\n",
    "def calc_magnitude(decoder_outputs, target_outputs):\n",
    "    max_penalty_magnitude = torch.tensor(10)\n",
    "  \n",
    "    decoded_output_symbols = []\n",
    "    decoded_target_symbols = []\n",
    "    detached_target_outputs = target_outputs.cpu().detach().numpy().squeeze()\n",
    "\n",
    "    for decoder_output in decoder_outputs:\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        decoded_output = eq.index2word[topi.item()]\n",
    "        decoded_output_symbols.append(decoded_output)\n",
    "    \n",
    "    # if any(i in [0, 1] for i in decoder_outputs):\n",
    "    #     print(\"Equation not valid 1\")\n",
    "    #     return max_penalty_magnitude\n",
    "\n",
    "    for i, target_output in enumerate(detached_target_outputs):\n",
    "        decoded_target = eq.index2word[target_output]\n",
    "        decoded_target_symbols.append(decoded_target)\n",
    "    \n",
    "    stringified_output = ''.join(decoded_output_symbols)\n",
    "    \n",
    "    # print(\"--- Target ---\")\n",
    "    # print(detached_target_outputs)\n",
    "    # print(decoded_target_symbols) \n",
    "\n",
    "    # print(\"--- Output ---\")\n",
    "    # print(decoder_outputs[0]) \n",
    "    # print(decoded_output_symbols) \n",
    "    # print(stringified_output)\n",
    "\n",
    "    if is_eq_valid(stringified_output) == False:\n",
    "        # print(\"Equation not valid 2\")\n",
    "        return max_penalty_magnitude\n",
    "\n",
    "    output_sequence = eq_to_seq(stringified_output, 9)\n",
    "\n",
    "    # if np.zeros(9) == np.array(output_sequence):\n",
    "    #     print(\"Equation not valid 3\")\n",
    "    #     return max_penalty_magnitude\n",
    "    # else:\n",
    "    stringified_target = ''.join(decoded_target_symbols[:-1])\n",
    "    # print(stringified_target)\n",
    "    target_sequence = eq_to_seq(stringified_target, 9)\n",
    "\n",
    "\n",
    "    \n",
    "    return compare_sequences(output_sequence, target_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), seq, eq)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion =nn.NLLLoss() #  converted_loss\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, calc_magnitude)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            # enablePrint()\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            # blockPrint()\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.0\n",
      "2.2222222222222223\n",
      "5.0\n",
      "4.555555555555555\n",
      "5.0\n",
      "4.666666666666667\n",
      "0m 11s (- 1m 47s) (100 10%) 411.4948\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.333333333333333\n",
      "0m 22s (- 1m 31s) (200 20%) 422.5660\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.333333333333333\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "0m 31s (- 1m 13s) (300 30%) 417.9584\n",
      "5.0\n",
      "3.6666666666666665\n",
      "4.777777777777778\n",
      "5.0\n",
      "3.888888888888889\n",
      "5.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "0m 39s (- 0m 59s) (400 40%) 347.1878\n",
      "4.666666666666667\n",
      "3.888888888888889\n",
      "4.666666666666667\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.888888888888889\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "3.3333333333333335\n",
      "5.0\n",
      "0m 51s (- 0m 51s) (500 50%) 377.4268\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.333333333333333\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "1m 2s (- 0m 41s) (600 60%) 422.5849\n",
      "4.555555555555555\n",
      "5.0\n",
      "5.0\n",
      "2.3333333333333335\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.0\n",
      "5.0\n",
      "1m 12s (- 0m 31s) (700 70%) 343.8889\n",
      "5.0\n",
      "2.3333333333333335\n",
      "4.666666666666667\n",
      "4.333333333333333\n",
      "5.0\n",
      "4.777777777777778\n",
      "4.555555555555555\n",
      "5.0\n",
      "1m 24s (- 0m 21s) (800 80%) 376.2519\n",
      "4.444444444444445\n",
      "4.888888888888889\n",
      "4.333333333333333\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "3.5555555555555554\n",
      "5.0\n",
      "3.3333333333333335\n",
      "5.0\n",
      "5.0\n",
      "1m 35s (- 0m 10s) (900 90%) 362.6055\n",
      "4.888888888888889\n",
      "5.0\n",
      "5.0\n",
      "4.888888888888889\n",
      "4.444444444444445\n",
      "5.0\n",
      "5.0\n",
      "2.5555555555555554\n",
      "4.333333333333333\n",
      "2.888888888888889\n",
      "5.0\n",
      "4.555555555555555\n",
      "5.0\n",
      "5.0\n",
      "2.3333333333333335\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "4.666666666666667\n",
      "1m 46s (- 0m 0s) (1000 100%) 347.1372\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(seq.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, eq.n_words).to(device)\n",
    "\n",
    "\n",
    "# blockPrint()\n",
    "training(encoder, decoder, 1000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_utils import tensorFromSentence\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "input_lang = seq\n",
    "output_lang = eq\n",
    "EOS_token = 0\n",
    "SOS_token = 1\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)  # this if or simply decoder\n",
    "                \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}