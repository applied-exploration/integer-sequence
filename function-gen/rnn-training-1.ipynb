{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)"
  },
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from models.rnn.encoder_decoder_gru import EncoderRNN, DecoderRNN\n",
    "from models.rnn.combined_networks import train\n",
    "from rnn_utils import tensorsFromPair\n",
    "from utils import showPlot, timeSince, asMinutes\n",
    "from lang import load_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "source": [
    "# Training Loops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq, seq, pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('24,28,32,36,40,44,48,52', '4*t+4+2*8'), ('36,37,38,39,40,41,42,43', '0+5*8-5+t')]\n24,28,32,36,40,44,48,52\n4*t+4+2*8\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:2])\n",
    "print(pairs[0][0])\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.typing import NDArray\n",
    "\n",
    "def normalize_0_1(a: np.ndarray) -> np.ndarray:\n",
    "    # Normalised [0,1]\n",
    "    return (a - np.min(a))/np.ptp(a)\n",
    "\n",
    "def normalize_1_255(a: np.ndarray) -> np.ndarray:\n",
    "    # Normalised [0,255] as integer: don't forget the parenthesis before astype(int)\n",
    "    return (255*(a - np.min(a))/np.ptp(a)).astype(int)\n",
    "\n",
    "def normalize_minus1_1(a: np.ndarray) -> np.ndarray:\n",
    "    # Normalised [-1,1]\n",
    "    return 2.*(a - np.min(a))/np.ptp(a)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequences(output_sequence: np.ndarray, target_sequence: np.ndarray) -> float:\n",
    "        magnitude: float = 0.0\n",
    "\n",
    "        # print(output_sequence)\n",
    "        # print(target_sequence)\n",
    "        combined_seq = np.array([output_sequence, target_sequence]) #concatenate((output_sequence, target_sequence))\n",
    "        norm_comb_seq = normalize_0_1(combined_seq)\n",
    "\n",
    "        norm_output_seq = norm_comb_seq[0]\n",
    "        norm_target_seq = norm_comb_seq[1]\n",
    "        # print(norm_comb_seq)\n",
    "        # print(norm_output_seq)\n",
    "        # print(norm_target_seq)\n",
    "        \n",
    "        for i, value in enumerate(norm_target_seq.tolist()):\n",
    "            magnitude += abs(value - norm_output_seq[i])#**2\n",
    "\n",
    "        # magnitude /= len(norm_target_seq)\n",
    "\n",
    "        return torch.tensor(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eq_to_seq, is_eq_valid\n",
    "\n",
    "def calc_magnitude(decoder_outputs, target_outputs):\n",
    "    max_penalty_magnitude = torch.tensor(9., dtype=torch.float64)\n",
    "  \n",
    "    decoded_output_symbols = []\n",
    "    decoded_target_symbols = []\n",
    "    detached_target_outputs = target_outputs.cpu().detach().numpy().squeeze()\n",
    "\n",
    "    for decoder_output in decoder_outputs:\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        decoded_output = eq.index2word[topi.item()]\n",
    "        decoded_output_symbols.append(decoded_output)\n",
    "    \n",
    "    for i, target_output in enumerate(detached_target_outputs):\n",
    "        decoded_target = eq.index2word[target_output]\n",
    "        decoded_target_symbols.append(decoded_target)\n",
    "    \n",
    "    stringified_output = ''.join(decoded_output_symbols)\n",
    "    \n",
    "    if is_eq_valid(stringified_output) == False:\n",
    "        return max_penalty_magnitude\n",
    "\n",
    "    output_sequence = eq_to_seq(stringified_output, 9)\n",
    "\n",
    "    if np.count_nonzero(output_sequence) < 1:\n",
    "        return max_penalty_magnitude\n",
    "    else:\n",
    "        stringified_target = ''.join(decoded_target_symbols[:-1])\n",
    "        target_sequence = eq_to_seq(stringified_target, 9)\n",
    "\n",
    "    return compare_sequences(np.array(output_sequence), np.array(target_sequence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, calc_magnitude = None):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), seq, eq)\n",
    "                      for i in range(n_iters)]\n",
    "    criterion =nn.NLLLoss() #  converted_loss\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, calc_magnitude)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            # enablePrint()\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            # blockPrint()\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 5s (- 4m 20s) (100 2%) 19.6826\n",
      "0m 9s (- 3m 43s) (200 4%) 14.8882\n",
      "0m 13s (- 3m 28s) (300 6%) 14.6629\n",
      "0m 17s (- 3m 20s) (400 8%) 14.5336\n",
      "0m 21s (- 3m 13s) (500 10%) 14.7804\n",
      "0m 25s (- 3m 8s) (600 12%) 14.7919\n",
      "0m 29s (- 3m 3s) (700 14%) 14.3958\n",
      "0m 34s (- 2m 59s) (800 16%) 14.6135\n",
      "0m 38s (- 2m 54s) (900 18%) 14.6739\n",
      "0m 42s (- 2m 50s) (1000 20%) 14.5331\n",
      "0m 46s (- 2m 45s) (1100 22%) 14.2140\n",
      "0m 51s (- 2m 42s) (1200 24%) 14.2733\n",
      "0m 55s (- 2m 38s) (1300 26%) 14.5426\n",
      "1m 0s (- 2m 34s) (1400 28%) 14.0034\n",
      "1m 4s (- 2m 29s) (1500 30%) 14.1626\n",
      "1m 8s (- 2m 24s) (1600 32%) 14.0883\n",
      "1m 12s (- 2m 20s) (1700 34%) 14.2953\n",
      "1m 16s (- 2m 15s) (1800 36%) 14.1584\n",
      "1m 20s (- 2m 10s) (1900 38%) 14.3359\n",
      "1m 24s (- 2m 6s) (2000 40%) 14.3164\n",
      "1m 28s (- 2m 1s) (2100 42%) 13.9198\n",
      "1m 32s (- 1m 57s) (2200 44%) 14.1523\n",
      "1m 36s (- 1m 53s) (2300 46%) 13.9615\n",
      "1m 40s (- 1m 49s) (2400 48%) 13.8521\n",
      "1m 45s (- 1m 45s) (2500 50%) 14.0578\n",
      "1m 49s (- 1m 40s) (2600 52%) 13.7391\n",
      "1m 53s (- 1m 36s) (2700 54%) 13.9265\n",
      "1m 58s (- 1m 33s) (2800 56%) 13.9273\n",
      "2m 3s (- 1m 29s) (2900 57%) 14.1652\n",
      "2m 8s (- 1m 25s) (3000 60%) 13.8521\n",
      "2m 13s (- 1m 21s) (3100 62%) 13.5930\n",
      "2m 18s (- 1m 17s) (3200 64%) 13.6644\n",
      "2m 22s (- 1m 13s) (3300 66%) 13.7757\n",
      "2m 26s (- 1m 9s) (3400 68%) 13.4602\n",
      "2m 31s (- 1m 4s) (3500 70%) 13.9134\n",
      "2m 35s (- 1m 0s) (3600 72%) 13.7945\n",
      "2m 40s (- 0m 56s) (3700 74%) 13.6789\n",
      "2m 44s (- 0m 52s) (3800 76%) 13.8718\n",
      "2m 49s (- 0m 47s) (3900 78%) 13.6329\n",
      "2m 53s (- 0m 43s) (4000 80%) 13.5285\n",
      "2m 57s (- 0m 38s) (4100 82%) 13.5693\n",
      "3m 1s (- 0m 34s) (4200 84%) 14.0148\n",
      "3m 5s (- 0m 30s) (4300 86%) 13.8804\n",
      "3m 9s (- 0m 25s) (4400 88%) 13.8581\n",
      "3m 13s (- 0m 21s) (4500 90%) 13.8967\n",
      "3m 17s (- 0m 17s) (4600 92%) 13.7900\n",
      "3m 21s (- 0m 12s) (4700 94%) 13.6668\n",
      "3m 25s (- 0m 8s) (4800 96%) 14.0776\n",
      "3m 30s (- 0m 4s) (4900 98%) 14.2550\n",
      "3m 33s (- 0m 0s) (5000 100%) 13.7153\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(seq.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, eq.n_words).to(device)\n",
    "\n",
    "training(encoder, decoder, 10000, print_every=1000, calc_magnitude = calc_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_utils import tensorFromSentence\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "input_lang = seq\n",
    "output_lang = eq\n",
    "EOS_token = 0\n",
    "SOS_token = 1\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)  # this if or simply decoder\n",
    "                \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        stringified_output = ''.join(decoded_words[:-1])\n",
    "        output_sequence = eq_to_seq(stringified_output, 9)\n",
    "\n",
    "        return decoded_words, output_sequence, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('=', pair[1])\n",
    "        print('>', pair[0])\n",
    "        output_words, output_sequence, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        output_sequence = ''.join(str(x)+',' for x in output_sequence)\n",
    "        print('<', output_sequence)\n",
    "        print('=', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "= t+9*t-t+5\n",
      "> 14,23,32,41,50,59,68,77\n",
      "< 1,32,243,1024,3125,7776,16807,32768,59049,\n",
      "= t * t * t * t * t <EOS>\n",
      "\n",
      "= 2*7*5*2*t\n",
      "> 140,280,420,560,700,840,980,1120\n",
      "< 1,32,243,1024,3125,7776,16807,32768,59049,\n",
      "= t * t * t * t * t <EOS>\n",
      "\n",
      "= t+t*2*t-7\n",
      "> -4,3,14,29,48,71,98,129\n",
      "< 0,4,18,48,100,180,294,448,648,\n",
      "= t * t * t - t * t <EOS>\n",
      "\n",
      "= 4-9*t-t-3\n",
      "> -9,-19,-29,-39,-49,-59,-69,-79\n",
      "< -1,-6,-15,-28,-45,-66,-91,-120,-153,\n",
      "= t - t * t - t * t <EOS>\n",
      "\n",
      "= 9+t+t*3*2\n",
      "> 16,23,30,37,44,51,58,65\n",
      "< 1,32,243,1024,3125,7776,16807,32768,59049,\n",
      "= t * t * t * t * t <EOS>\n",
      "\n",
      "= 2+t+3*7-7\n",
      "> 17,18,19,20,21,22,23,24\n",
      "< 2,12,36,80,150,252,392,576,810,\n",
      "= t * t * t + t * t <EOS>\n",
      "\n",
      "= t-4*1*t-1\n",
      "> -4,-7,-10,-13,-16,-19,-22,-25\n",
      "< -1,-6,-15,-28,-45,-66,-91,-120,-153,\n",
      "= t - t * t - t * t <EOS>\n",
      "\n",
      "= 3*4-t-0*t\n",
      "> 11,10,9,8,7,6,5,4\n",
      "< -1,-6,-15,-28,-45,-66,-91,-120,-153,\n",
      "= t - t * t - t * t <EOS>\n",
      "\n",
      "= 5-t+1*6+1\n",
      "> 11,10,9,8,7,6,5,4\n",
      "< -1,-6,-15,-28,-45,-66,-91,-120,-153,\n",
      "= t - t * t - t * t <EOS>\n",
      "\n",
      "= 1*t*7+8-t\n",
      "> 14,20,26,32,38,44,50,56\n",
      "< 1,32,243,1024,3125,7776,16807,32768,59049,\n",
      "= t * t * t * t * t <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}