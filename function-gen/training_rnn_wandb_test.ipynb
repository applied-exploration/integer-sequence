{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from models.rnn.rnn_plain import RNN_Plain\r\n",
    "from models.rnn.rnn_attention import RNN_Attention\r\n",
    "\r\n",
    "from lang import load_data_int_seq\r\n",
    "from utils import accuracy_score\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import wandb\r\n",
    "wandb.login()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maexploration\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "output_lang, input_lang, train, X_test, y_test = load_data_int_seq()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plain RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "my_config ={\"symbols\": \"+*-0123456789t\", \r\n",
    "\"output_sequence_length\": 9, \r\n",
    "\"encoded_seq_length\": 9, \r\n",
    "\"num_epochs\": 100, \r\n",
    "\"input_size\": input_lang.n_words, \r\n",
    "\"hidden_size\": 256, \r\n",
    "\"output_size\": output_lang.n_words, \r\n",
    "\"embedding_size\": 256, \r\n",
    "\"batch_size\": 32, \r\n",
    "\"num_gru_layers\": 2,\r\n",
    "\"dropout_prob\": 0.3,\r\n",
    "\"calc_magnitude_on\":False}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "wandb.init(project=\"test-jupyter-projo\",  config=my_config)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">soft-jazz-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aexploration/test-jupyter-projo\" target=\"_blank\">https://wandb.ai/aexploration/test-jupyter-projo</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aexploration/test-jupyter-projo/runs/vl890dwk\" target=\"_blank\">https://wandb.ai/aexploration/test-jupyter-projo/runs/vl890dwk</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\danie\\Code\\ai\\research company\\integer-sequence\\function-gen\\wandb\\run-20210712_173215-vl890dwk</code><br/><br/>\n",
       "            "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x17067214088>"
      ],
      "text/html": [
       "<h1>Run(vl890dwk)</h1><iframe src=\"https://wandb.ai/aexploration/test-jupyter-projo/runs/vl890dwk\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "algo = RNN_Plain(**my_config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(4300, 256)\n",
      "  (gru): GRU(256, 256, num_layers=2, dropout=0.3)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embedding): Embedding(16, 256)\n",
      "  (gru): GRU(256, 256, num_layers=2, dropout=0.3)\n",
      "  (out): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "algo.train(input_lang, output_lang, train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0m 7s (- 1m 6s) (10 10%) 2.6407\n",
      "0m 9s (- 0m 39s) (20 20%) 2.4831\n",
      "0m 12s (- 0m 29s) (30 30%) 2.4604\n",
      "0m 15s (- 0m 23s) (40 40%) 2.4498\n",
      "0m 18s (- 0m 18s) (50 50%) 2.4184\n",
      "0m 20s (- 0m 13s) (60 60%) 2.3876\n",
      "0m 23s (- 0m 10s) (70 70%) 2.3749\n",
      "0m 26s (- 0m 6s) (80 80%) 2.3674\n",
      "0m 28s (- 0m 3s) (90 90%) 2.3332\n",
      "0m 31s (- 0m 0s) (100 100%) 2.3448\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:10]"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(pred, y_test[:1000])\r\n",
    "if wandb.run is not None:\r\n",
    "    wandb.finish()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import test_rnn_plain"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plain RNN with Magnitude loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "magn_algo = RNN_Plain(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\r\n",
    "magn_algo.train(input_lang, output_lang, train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = magn_algo.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Â Attention-based"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "algo_attn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=False)\r\n",
    "algo_attn.train(input_lang, output_lang, train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = algo_attn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attention with magnitude loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "algo_attn_magn = RNN_Attention(symbols = \"+*-0123456789t\", output_sequence_length = 9, encoded_seq_length = 9, num_epochs= 5000, input_size=input_lang.n_words, hidden_size=512, output_size=output_lang.n_words, calc_magnitude_on=True)\n",
    "algo_attn_magn.train(input_lang, output_lang, train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = algo_attn_magn.infer(input_lang, output_lang, X_test[:1000])\r\n",
    "pred[:25]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(pred, y_test[:1000])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Stuff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "m = nn.LogSoftmax()\r\n",
    "input = torch.randn(2, 3)\r\n",
    "print(input)\r\n",
    "output = m(input)\r\n",
    "print(output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2D loss example (used, for example, with image inputs)\r\n",
    "N, C = 5, 4\r\n",
    "loss = nn.NLLLoss()\r\n",
    "\r\n",
    "# input is of size N x C x height x width\r\n",
    "data = torch.randn(N, 16, 10, 10)\r\n",
    "conv = nn.Conv2d(16, C, (3, 3))\r\n",
    "m = nn.LogSoftmax(dim=1)\r\n",
    "\r\n",
    "# print(data.shape)\r\n",
    "activated = m(conv(data))\r\n",
    "print(\"output: \", activated.shape)\r\n",
    "\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\r\n",
    "print(\"target: \", target.shape)\r\n",
    "output = loss(activated, target)\r\n",
    "\r\n",
    "# output.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "m = nn.LogSoftmax(dim=1)\r\n",
    "loss = nn.NLLLoss()\r\n",
    "# input is of size N x C = 3 x 5\r\n",
    "# input = minibatchsize, number of categories\r\n",
    "\r\n",
    "input = torch.randn(3, 5, requires_grad=True)\r\n",
    "# print(input.shape)\r\n",
    "activation = m(input)\r\n",
    "print(activation.shape)\r\n",
    "# each element in target has to have 0 <= value < C\r\n",
    "target = torch.tensor([1, 0, 4])\r\n",
    "print(target.shape)\r\n",
    "output = loss(activation, target)\r\n",
    "# output.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from line_profiler import LineProfiler\r\n",
    "\r\n",
    "stuff_to_evaluate = [1,2,3]\r\n",
    "def function_to_evaluate(stuff_to_evaluate):\r\n",
    "    pass\r\n",
    "\r\n",
    "lp = LineProfiler()\r\n",
    "lp_wrapper = lp(function_to_evaluate)\r\n",
    "lp_wrapper(stuff_to_evaluate)\r\n",
    "lp.print_stats()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21b14e6ae810b98687c42101764fbc6ed2f749f10b37141b42930ea65db4f89b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('drlnd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}